{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/agavrilenko/anaconda3/lib/python3.6/site-packages/xgboost\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.dirname(xgb.__file__)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(xgboost.training.train)\n",
    "#help(xgb.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = loadtxt('data/data.txt', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label = y_train, silent= True)\n",
    "\n",
    "deval = xgb.DMatrix(data = X_test, label = y_test, silent= True)\n",
    "# evals_list = []\n",
    "# evals_list.append((deval, \"eval matrix\"))\n",
    "num_epochs = 200\n",
    "params = {}\n",
    "params['num_boost_round'] = num_epochs\n",
    "params['early_stopping_rounds'] = 1000\n",
    "#params['verbose_eval'] = 1\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['evals_result'] = {}\n",
    "params['max_depth'] = 3\n",
    "\n",
    "params['subsample'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_previous = 0.1\n",
    "cooldown_counter = 0\n",
    "best = 100\n",
    "progress = dict()\n",
    "wait = 0 \n",
    "\n",
    "def reduceLRonPlateau(i,n):\n",
    "\n",
    "    factor = 0.3\n",
    "    min_lr = 1e-30\n",
    "    min_delta = 1e-4\n",
    "    patience = 3\n",
    "    verbose = 0\n",
    "    cooldown = 0    \n",
    "    def in_cooldown():\n",
    "            return cooldown_counter > 0\n",
    "    \n",
    "    def _reset():\n",
    "        cooldown_counter = cooldown\n",
    "        wait = 0\n",
    "        return wait, cooldown_counter\n",
    "    \n",
    "    def checker(): \n",
    "        global wait\n",
    "        global best\n",
    "        global learning_rate_previous\n",
    "        global cooldown_counter\n",
    "        new_learning_rate = learning_rate_previous\n",
    "        \n",
    "        if (i == 0):\n",
    "            wait, cooldown_counter = _reset()\n",
    "            print(\"Initialization...\")           \n",
    "            \n",
    "        if (i>0):\n",
    "            previous_loss = progress['eval']['logloss'][i-1]\n",
    "            if in_cooldown():\n",
    "                cooldown_counter -= 1\n",
    "                wait = 0\n",
    "            \n",
    "            else:\n",
    "                if (previous_loss < best- min_delta):\n",
    "                    best= previous_loss\n",
    "                    wait = 0\n",
    "                \n",
    "                else:\n",
    "                    wait+=1\n",
    "                    if wait > patience:\n",
    "                        if old_lr > min_lr:\n",
    "                            new_learning_rate = learning_rate_previous * factor\n",
    "                            new_learning_rate = max(new_learning_rate, min_lr)\n",
    "                           \n",
    "                            cooldown_counter = cooldown\n",
    "                            wait = 0\n",
    "                        \n",
    "        return new_learning_rate\n",
    "\n",
    "   \n",
    "    new_learning_rate = checker()\n",
    "    global learning_rate_previous\n",
    "    #print(\"iter: \", i,\" old_lr: \" ,learning_rate_previous, \" new_lr: \", new_learning_rate)\n",
    "    \n",
    "    learning_rate_previous = new_learning_rate\n",
    "        \n",
    "    return 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_gbm(dtrain, dvalid, param, evals_result, learning_rate):\n",
    "    # check training arguments in param\n",
    "    n_round = param.get('num_boost_round', 100)\n",
    "    early_stop = param.get('early_stopping_rounds', 0)\n",
    "    verbose_eval = param.get('verbose_eval', 0)\n",
    "    # specify validations set to watch performance\n",
    "    watchlist = [(dtrain,'train') ,(deval,'eval')]\n",
    "    #callbacks_list = [learning_rates]\n",
    "    \n",
    "    bst = xgb.train(params=param,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=n_round,\n",
    "            evals=watchlist,\n",
    "            early_stopping_rounds=early_stop,\n",
    "            verbose_eval = verbose_eval,\n",
    "            evals_result = evals_result, \n",
    "            callbacks = [xgb.callback.reset_learning_rate(reduceLRonPlateau)])\n",
    "    print(\"done\")                  \n",
    "    return bst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model1 = run_gbm(dtrain, deval, params,progress, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eta=0.2, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=200, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "\n",
    "model = XGBClassifier(n_estimators=num_epochs, learning_rate=0.1, subsample=1, eta = 0.2 )\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrieve performance metrics\n",
    "# results = model.evals_result()\n",
    "# #results1 = model1.evals_result()\n",
    "# epochs = len(results['validation_0']['error'])\n",
    "# x_axis = range(0, 200)\n",
    "\n",
    "# # plot log loss\n",
    "# fig, ax = pyplot.subplots(figsize=(10, 6))\n",
    "# ax.plot(x_axis, results['validation_0']['logloss'][:200:], label='Train')\n",
    "# ax.plot(x_axis, results['validation_1']['logloss'][:200:], label='Eval')\n",
    "# ax.plot(x_axis, progress['train']['logloss'][:200:], label = 'customTrain')\n",
    "# ax.plot(x_axis, progress['eval']['logloss'][:200:], label = 'customEval')\n",
    "# ax.legend()\n",
    "# pyplot.ylabel('Log Loss')\n",
    "# pyplot.title('XGBoost Log Loss')\n",
    "\n",
    "# pyplot.show()\n",
    "# print(\"iter: \", progress['eval']['logloss'][:200:].index(min(progress['eval']['logloss'][:200:])), \" min customEval:\", min(progress['eval']['logloss'][:100:]))\n",
    "# print(\"iter: \", results['validation_1']['logloss'][:200:].index(min(results['validation_1']['logloss'][:200:])), \" min Eval:\", min(results['validation_1']['logloss'][:100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
